{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132681fa-7b1f-4ff5-a55e-9c90353188a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shapkin/effective-inference\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b67a0-fe46-4104-a66e-bf8bdabb756c",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570ebef6-a677-45ff-8ee9-69f8ee0747fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import yaml\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset_cache import cache_embeddings, get_dataset_for_regression, build_dataset_from_cached, load_cached_dataset\n",
    "from utils.dataset_cache import build_dict_dataset_from_cached\n",
    "from utils.prepare_dataset import load_datasets, cut_datasets\n",
    "from utils.config import ConfigWrapper\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "from numpy.random import shuffle\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e31b89-adfc-4ecf-90b0-b0fa10375fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.attentions.bert.linear import BertWrapperLin, LinearClassifierBertAttention, LinearAttention\n",
    "from utils.dataset_utils import get_dict_batch, prepare_batches\n",
    "from utils.train_linear_utils import train_epoch, eval_epoch, plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d904b-77f3-4850-85e9-2a32cc667fc4",
   "metadata": {},
   "source": [
    "## Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04b0aa1-8b62-467c-b551-661a0dcb150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.yaml'\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = ConfigWrapper(yaml.load(f, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42217fc-f58a-4a04-9280-52e5cfffdb2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_name, max_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgeneral\u001b[38;5;241m.\u001b[39mmax_len)\n\u001b[0;32m----> 2\u001b[0m initial_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:2014\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2012\u001b[0m     )\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2014\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/effective-inference-puaXtOsB-py3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model.model_name, max_length=config.general.max_len)\n",
    "initial_model = AutoModel.from_pretrained(config.model.model_name).to(config.general.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968d196-e199-435d-9054-a13c94d11210",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_datasets = load_datasets(config.data.eval_datasets, config.data.cut_size)\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f751ad-9be8-4158-9b00-968a3432917f",
   "metadata": {},
   "source": [
    "## MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3692e76f-71a8-4eaa-83d4-15ec0d67e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71adb52e57f74eeca2feb98be049c0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_idx, dataset_name, dataset = 0, 'mrpc', eval_datasets['mrpc']\n",
    "layer2norm = {}\n",
    "for ex in tqdm(dataset['train'], total=len(dataset['train']), position=True, leave=True):\n",
    "    field1, field2 = config.data.eval_datasets_fields[dataset_idx]\n",
    "    if field2 != '':\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        ex[field2],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "    else:\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = initial_model(encoded_inputs, output_hidden_states=True, output_attentions=True)\n",
    "\n",
    "    for layer in range(len(outputs.hidden_states) - 1):\n",
    "        if layer not in layer2norm:\n",
    "            layer2norm[layer] = []\n",
    "        layer_output = outputs.hidden_states[layer][0]\n",
    "        for seq_idx in range(outputs.hidden_states[layer][0].shape[0]):\n",
    "            curr_emb = outputs.hidden_states[layer+1][0][seq_idx]\n",
    "            prev_emb = outputs.hidden_states[layer][0][seq_idx]\n",
    "            \n",
    "            layer2norm[layer].append(torch.norm(curr_emb-prev_emb).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47e7f73d-5256-4c5f-b2bd-d31acb88b9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mean and median: 9.121970471242427 ( 9.223304271697998 )\n",
      "1 mean and median: 8.349919297009167 ( 8.686412811279297 )\n",
      "2 mean and median: 8.354943535188614 ( 8.188782691955566 )\n",
      "3 mean and median: 8.308292512355528 ( 8.24538278579712 )\n",
      "4 mean and median: 8.266356978578083 ( 8.429078578948975 )\n",
      "5 mean and median: 8.149031351913937 ( 8.166177749633789 )\n",
      "6 mean and median: 8.319523116100328 ( 8.416105270385742 )\n",
      "7 mean and median: 8.159478774294886 ( 8.258448600769043 )\n",
      "8 mean and median: 7.920676039774069 ( 7.981983184814453 )\n",
      "9 mean and median: 8.853833924702794 ( 8.73741102218628 )\n",
      "10 mean and median: 7.909920914453066 ( 7.964186668395996 )\n",
      "11 mean and median: 11.588137592496066 ( 11.739653587341309 )\n"
     ]
    }
   ],
   "source": [
    "for layer, norms in layer2norm.items():\n",
    "    print(f'{layer} mean and median:', np.mean(norms), '(', np.median(norms), ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b95dbe-abd1-440e-8cbe-053a86923a02",
   "metadata": {},
   "source": [
    "## WIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ac57ce6-ee58-4cfc-91a8-dfacfa24590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36748427d9149d787bb72da82cfb68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_idx, dataset_name, dataset = 1, 'wic', eval_datasets['wic']\n",
    "layer2norm = {}\n",
    "for ex in tqdm(dataset['train'], total=len(dataset['train']), position=True, leave=True):\n",
    "    field1, field2 = config.data.eval_datasets_fields[dataset_idx]\n",
    "    if field2 != '':\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        ex[field2],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "    else:\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = initial_model(encoded_inputs, output_hidden_states=True, output_attentions=True)\n",
    "\n",
    "    for layer in range(len(outputs.hidden_states) - 1):\n",
    "        if layer not in layer2norm:\n",
    "            layer2norm[layer] = []\n",
    "        layer_output = outputs.hidden_states[layer][0]\n",
    "        for seq_idx in range(outputs.hidden_states[layer][0].shape[0]):\n",
    "            curr_emb = outputs.hidden_states[layer+1][0][seq_idx]\n",
    "            prev_emb = outputs.hidden_states[layer][0][seq_idx]\n",
    "            \n",
    "            layer2norm[layer].append(torch.norm(curr_emb-prev_emb).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a10feb75-c5f0-4d91-abb8-b1bb24945575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mean and median: 8.827095547197262 ( 8.848946571350098 )\n",
      "1 mean and median: 7.738413257428731 ( 7.8639092445373535 )\n",
      "2 mean and median: 8.21751114782759 ( 7.867585182189941 )\n",
      "3 mean and median: 7.696125160249789 ( 7.674619197845459 )\n",
      "4 mean and median: 7.172252207408471 ( 7.515017509460449 )\n",
      "5 mean and median: 7.48639344526253 ( 7.649768829345703 )\n",
      "6 mean and median: 7.841299281363784 ( 8.230294227600098 )\n",
      "7 mean and median: 7.827368092935812 ( 8.151829719543457 )\n",
      "8 mean and median: 7.453597766049063 ( 7.750354290008545 )\n",
      "9 mean and median: 8.123992402132705 ( 8.030667304992676 )\n",
      "10 mean and median: 7.14757240141516 ( 7.269410133361816 )\n",
      "11 mean and median: 10.794832546460642 ( 10.961954116821289 )\n"
     ]
    }
   ],
   "source": [
    "for layer, norms in layer2norm.items():\n",
    "    print(f'{layer} mean and median:', np.mean(norms), '(', np.median(norms), ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513a935-b1e0-4ca6-acdd-f9523fe9cc89",
   "metadata": {},
   "source": [
    "## IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12a3bb51-d904-4787-a446-02460634799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_datasets = load_datasets(config.data.train_datasets, config.data.cut_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "014f1299-a816-4a77-8c8c-64e5e03000c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b70995190491baed689ef6742c4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_idx, dataset_name, dataset = 0, 'imdb', eval_datasets['imdb']\n",
    "layer2norm = {}\n",
    "for ex in tqdm(dataset['train'], total=len(dataset['train']), position=True, leave=True):\n",
    "    field1, field2 = config.data.train_datasets_fields[dataset_idx]\n",
    "    if field2 != '':\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        ex[field2],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "    else:\n",
    "        encoded_inputs = tokenizer.encode(\n",
    "                        ex[field1],\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(config.general.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = initial_model(encoded_inputs, output_hidden_states=True, output_attentions=True)\n",
    "\n",
    "    for layer in range(len(outputs.hidden_states) - 1):\n",
    "        if layer not in layer2norm:\n",
    "            layer2norm[layer] = []\n",
    "        layer_output = outputs.hidden_states[layer][0]\n",
    "        for seq_idx in range(outputs.hidden_states[layer][0].shape[0]):\n",
    "            curr_emb = outputs.hidden_states[layer+1][0][seq_idx]\n",
    "            prev_emb = outputs.hidden_states[layer][0][seq_idx]\n",
    "            \n",
    "            layer2norm[layer].append(torch.norm(curr_emb-prev_emb).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "313f04ac-0117-4748-ac5e-b2b2afb439ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mean and median: 8.561740641097886 ( 8.603800296783447 )\n",
      "1 mean and median: 8.607935406028636 ( 8.691346168518066 )\n",
      "2 mean and median: 8.554685527824564 ( 8.430185317993164 )\n",
      "3 mean and median: 8.627527011758934 ( 8.421025276184082 )\n",
      "4 mean and median: 8.417464881664007 ( 8.290224552154541 )\n",
      "5 mean and median: 8.634323292065046 ( 8.527114868164062 )\n",
      "6 mean and median: 8.781677480413382 ( 8.685733795166016 )\n",
      "7 mean and median: 8.8651576286237 ( 8.83482313156128 )\n",
      "8 mean and median: 8.730750874322444 ( 8.740266799926758 )\n",
      "9 mean and median: 9.197371562321866 ( 9.180856704711914 )\n",
      "10 mean and median: 8.137803444909565 ( 8.145401954650879 )\n",
      "11 mean and median: 11.946552854364535 ( 12.052977561950684 )\n"
     ]
    }
   ],
   "source": [
    "for layer, norms in layer2norm.items():\n",
    "    print(f'{layer} mean and median:', np.mean(norms), '(', np.median(norms), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8905b-60ef-44b3-a489-dd4a4e86fe72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e1383-7e41-4e6a-99e8-ddde2a6b53c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fc79e-dc63-4207-b9b8-cefd4807ae14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84673be6-7f4a-4cf3-947f-b912a2ad3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "field1, field2 = config.data.eval_datasets_fields[dataset_idx]\n",
    "if field2 != '':\n",
    "    encoded_inputs = tokenizer.encode(\n",
    "                    ex[field1],\n",
    "                    ex[field2],\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                ).to(config.general.device)\n",
    "else:\n",
    "    encoded_inputs = tokenizer.encode(\n",
    "                    ex[field1],\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                ).to(config.general.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78a3cc-c12c-4cf8-8dbb-7cad3c7dbe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abe8c583-37c1-4d9c-83c1-a0756ee46c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_pbar = lambda x, y: tqdm(x, leave=True, position=0, total=len(x), desc=f'{y}')\n",
    "def get_cls_embeddings_for_dataset(dataset_idx, dataset_name, dataset, config, tokenizer, model,\n",
    "                                   pbar_func=tqdm_pbar):\n",
    "    collected_embeddings = defaultdict(list)\n",
    "\n",
    "    for split, data in eval_datasets[dataset_name].items():\n",
    "        pbar = pbar_func(list(enumerate(data)), f\"{split} {dataset_name}\") if pbar_func is not None else data\n",
    "        for ex_idx, ex in pbar:\n",
    "            field1, field2 = config.data.eval_datasets_fields[dataset_idx]\n",
    "            if field2 != '':\n",
    "                encoded_inputs = tokenizer.encode(\n",
    "                                ex[field1],\n",
    "                                ex[field2],\n",
    "                                truncation=True,\n",
    "                                return_tensors='pt'\n",
    "                            ).to(config.general.device)\n",
    "            else:\n",
    "                encoded_inputs = tokenizer.encode(\n",
    "                                ex[field1],\n",
    "                                truncation=True,\n",
    "                                return_tensors='pt'\n",
    "                            ).to(config.general.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(encoded_inputs)\n",
    "\n",
    "            # Get the embedding of the [CLS] token\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "            # Append the [CLS] embedding to the list\n",
    "            collected_embeddings[split].append(cls_embedding)\n",
    "    return collected_embeddings\n",
    "\n",
    "def train_linear(X_train, y_train):\n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "def evaluate_classifier(classifier, X, y=None):\n",
    "    predictions = classifier.predict(X)\n",
    "    return predictions\n",
    "\n",
    "def get_metrics_report(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred,  average='weighted')\n",
    "    print('Weighted F1', f1)\n",
    "    print('Accuracy', accuracy)\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a22fe679-5774-4854-883d-a8461c4400d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def check_results(custom_model, initial_model, datasets, config):\n",
    "    for dataset_idx, (dataset_name, dataset) in enumerate(datasets.items()):\n",
    "        print(f\"{dataset_name}\\n\")\n",
    "\n",
    "        print('Original')\n",
    "\n",
    "        dataset_embeddings_orig = get_cls_embeddings_for_dataset(\n",
    "            dataset_idx, \n",
    "            dataset_name,\n",
    "            dataset, \n",
    "            config,\n",
    "            tokenizer, \n",
    "            initial_model)\n",
    "        \n",
    "        train_dataset_embeddings = torch.cat(dataset_embeddings_orig['train'], dim=0)\n",
    "        valid_dataset_embeddings = torch.cat(dataset_embeddings_orig['validation'], dim=0)\n",
    "        test_dataset_embeddings = torch.cat(dataset_embeddings_orig['test'], dim=0)\n",
    "        \n",
    "        classif = train_linear(train_dataset_embeddings.cpu(), [el['label'] for el in dataset['train']])\n",
    "        valid_preds = evaluate_classifier(classif, valid_dataset_embeddings.cpu())\n",
    "        print('Validation evaluation:\\n')\n",
    "        get_metrics_report([el['label'] for el in dataset['validation']], valid_preds)\n",
    "        # print(train_dataset_embeddings.shape)\n",
    "\n",
    "        \n",
    "        print('\\nLinear:')\n",
    "        \n",
    "        dataset_embeddings_custom = get_cls_embeddings_for_dataset(\n",
    "            dataset_idx, \n",
    "            dataset_name,\n",
    "            dataset, \n",
    "            config,\n",
    "            tokenizer, \n",
    "            custom_model)\n",
    "        \n",
    "        train_dataset_embeddings = torch.cat(dataset_embeddings_custom['train'], dim=0)\n",
    "        valid_dataset_embeddings = torch.cat(dataset_embeddings_custom['validation'], dim=0)\n",
    "        test_dataset_embeddings = torch.cat(dataset_embeddings_custom['test'], dim=0)\n",
    "\n",
    "\n",
    "        classif = train_linear(train_dataset_embeddings.cpu(), [el['label'] for el in dataset['train']])\n",
    "        valid_preds = evaluate_classifier(classif, valid_dataset_embeddings.cpu())\n",
    "        print('Validation evaluation:\\n')\n",
    "        get_metrics_report([el['label'] for el in dataset['validation']], valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db790ba-7015-4e58-8161-abbea8dd4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = initial_model.to(config.general.device)\n",
    "linear_model = linear_model.to(config.general.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a78ecb7d-63d6-4b51-9771-e07b38352a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrpc\n",
      "\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc5ded640cd43569bf485a406438d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train mrpc:   0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e32284f1674977a11f0b2281fcb590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation mrpc:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fafa6a7bca4df692a6ca08c7fde50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test mrpc:   0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.688181620007579\n",
      "Accuracy 0.6936274509803921\n",
      "-------------------------------\n",
      "\n",
      "Linear:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3e74027aa745dc914c158e70067bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train mrpc:   0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc07ded229714f7dbd86201ebb132122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation mrpc:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200a8daedd4f43658d15acaae8c4994f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test mrpc:   0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.6226437943598493\n",
      "Accuracy 0.6372549019607843\n",
      "-------------------------------\n",
      "wic\n",
      "\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70fc92908ad4160969948ac202cab92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train wic:   0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea31becc4a8452f9d93d6e9e2148011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation wic:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13ea84c5fb04b3190e8b191d0d6db20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test wic:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.6009986605735895\n",
      "Accuracy 0.6018808777429467\n",
      "-------------------------------\n",
      "\n",
      "Linear:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c97e0b6871487889fbf2d322aa20e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train wic:   0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d72b17aeea4816be47ff26618e49b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation wic:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433058ce5bad4ef8966a7f8967b9113b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test wic:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.48395963171933964\n",
      "Accuracy 0.4843260188087774\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "check_results(linear_model, initial_model, eval_datasets, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9d6f7-7774-4860-bc09-89cecca61d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
