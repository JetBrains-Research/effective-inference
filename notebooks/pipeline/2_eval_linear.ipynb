{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132681fa-7b1f-4ff5-a55e-9c90353188a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shapkin/effective-inference\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b67a0-fe46-4104-a66e-bf8bdabb756c",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570ebef6-a677-45ff-8ee9-69f8ee0747fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import yaml\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.dataset_cache import cache_embeddings, get_dataset_for_regression, build_dataset_from_cached, load_cached_dataset\n",
    "from utils.dataset_cache import build_dict_dataset_from_cached\n",
    "from utils.prepare_dataset import load_datasets, cut_datasets\n",
    "from utils.config import ConfigWrapper\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import Tuple, List, Dict, Optional, Union\n",
    "from numpy.random import shuffle\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e31b89-adfc-4ecf-90b0-b0fa10375fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.attentions.bert.linear import BertWrapperLin, LinearClassifierBertAttention, LinearAttention\n",
    "from utils.dataset_utils import get_dict_batch, prepare_batches\n",
    "from utils.train_linear_utils import train_epoch, eval_epoch, plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d904b-77f3-4850-85e9-2a32cc667fc4",
   "metadata": {},
   "source": [
    "## Project configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04b0aa1-8b62-467c-b551-661a0dcb150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.yaml'\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = ConfigWrapper(yaml.load(f, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42217fc-f58a-4a04-9280-52e5cfffdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model.model_name, max_length=config.general.max_len)\n",
    "initial_model = AutoModel.from_pretrained(config.model.model_name).to(config.general.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e968d196-e199-435d-9054-a13c94d11210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mrpc': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "         num_rows: 3668\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "         num_rows: 408\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "         num_rows: 1725\n",
       "     })\n",
       " }),\n",
       " 'wic': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
       "         num_rows: 5428\n",
       "     })\n",
       "     validation: Dataset({\n",
       "         features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
       "         num_rows: 638\n",
       "     })\n",
       "     test: Dataset({\n",
       "         features: ['word', 'sentence1', 'sentence2', 'start1', 'start2', 'end1', 'end2', 'idx', 'label'],\n",
       "         num_rows: 1400\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_datasets = load_datasets(config.data.eval_datasets, config.data.cut_size)\n",
    "eval_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f751ad-9be8-4158-9b00-968a3432917f",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae194ba-c00f-46e6-bebb-a7fc3f8d99f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = BertWrapperLin(initial_model, LinearClassifierBertAttention, config, layer_nums=[8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "befc4c6d-6aef-48b8-8ec9-b5c4b4c25aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_linear_modules(config, linear_model):\n",
    "    for layer_num, bert_att in enumerate(linear_model.bert_model.encoder.layer):\n",
    "        for param_name, param in bert_att.named_modules():\n",
    "            if '.' in param_name and 'linear_model' in param_name.split('.')[-1]:\n",
    "                head_num = int(param_name.split('_')[-1])\n",
    "                save_pattern = f\"{config.data.model_save_pattern}_{layer_num}_{head_num}\"\n",
    "                param.load_state_dict(torch.load(f'{config.data.data_path}/linear_models/{save_pattern}/model.pth'), strict=False)\n",
    "\n",
    "def init_linear_modules2(config, linear_model):\n",
    "    for layer_num, bert_att in enumerate(linear_model.bert_model.encoder.layer):\n",
    "        for param_name, param in bert_att.named_modules():\n",
    "            if '.' in param_name and 'linear_model' in param_name.split('.')[-1]:\n",
    "                save_pattern = f\"{config.data.model_save_pattern}_{layer_num}\"\n",
    "                param.load_state_dict(torch.load(f'{config.data.data_path}/linear_models/{save_pattern}/model.pth'), strict=False)\n",
    "\n",
    "if config.attention_config.split_heads or config.attention_config.model_for_each_head:\n",
    "    init_linear_modules(config, linear_model)\n",
    "else:\n",
    "    init_linear_modules2(config, linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78a3cc-c12c-4cf8-8dbb-7cad3c7dbe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abe8c583-37c1-4d9c-83c1-a0756ee46c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_pbar = lambda x, y: tqdm(x, leave=True, position=0, total=len(x), desc=f'{y}')\n",
    "def get_cls_embeddings_for_dataset(dataset_idx, dataset_name, dataset, config, tokenizer, model,\n",
    "                                   pbar_func=tqdm_pbar):\n",
    "    collected_embeddings = defaultdict(list)\n",
    "\n",
    "    for split, data in eval_datasets[dataset_name].items():\n",
    "        pbar = pbar_func(list(enumerate(data)), f\"{split} {dataset_name}\") if pbar_func is not None else data\n",
    "        for ex_idx, ex in pbar:\n",
    "            field1, field2 = config.data.eval_datasets_fields[dataset_idx]\n",
    "            if field2 != '':\n",
    "                encoded_inputs = tokenizer.encode(\n",
    "                                ex[field1],\n",
    "                                ex[field2],\n",
    "                                truncation=True,\n",
    "                                return_tensors='pt'\n",
    "                            ).to(config.general.device)\n",
    "            else:\n",
    "                encoded_inputs = tokenizer.encode(\n",
    "                                ex[field1],\n",
    "                                truncation=True,\n",
    "                                return_tensors='pt'\n",
    "                            ).to(config.general.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(encoded_inputs)\n",
    "\n",
    "            # Get the embedding of the [CLS] token\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "            # Append the [CLS] embedding to the list\n",
    "            collected_embeddings[split].append(cls_embedding)\n",
    "    return collected_embeddings\n",
    "\n",
    "def train_linear(X_train, y_train):\n",
    "    classifier = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "def evaluate_classifier(classifier, X, y=None):\n",
    "    predictions = classifier.predict(X)\n",
    "    return predictions\n",
    "\n",
    "def get_metrics_report(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred,  average='weighted')\n",
    "    print('Weighted F1', f1)\n",
    "    print('Accuracy', accuracy)\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22fe679-5774-4854-883d-a8461c4400d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def check_results(custom_model, initial_model, datasets, config):\n",
    "    for dataset_idx, (dataset_name, dataset) in enumerate(datasets.items()):\n",
    "        print(f\"{dataset_name}\\n\")\n",
    "\n",
    "        print('Original')\n",
    "\n",
    "        dataset_embeddings_orig = get_cls_embeddings_for_dataset(\n",
    "            dataset_idx, \n",
    "            dataset_name,\n",
    "            dataset, \n",
    "            config,\n",
    "            tokenizer, \n",
    "            initial_model)\n",
    "        \n",
    "        train_dataset_embeddings = torch.cat(dataset_embeddings_orig['train'], dim=0)\n",
    "        valid_dataset_embeddings = torch.cat(dataset_embeddings_orig['validation'], dim=0)\n",
    "        test_dataset_embeddings = torch.cat(dataset_embeddings_orig['test'], dim=0)\n",
    "        \n",
    "        classif = train_linear(train_dataset_embeddings.cpu(), [el['label'] for el in dataset['train']])\n",
    "        valid_preds = evaluate_classifier(classif, valid_dataset_embeddings.cpu())\n",
    "        print('Validation evaluation:\\n')\n",
    "        get_metrics_report([el['label'] for el in dataset['validation']], valid_preds)\n",
    "        # print(train_dataset_embeddings.shape)\n",
    "\n",
    "        \n",
    "        print('\\nLinear:')\n",
    "        \n",
    "        dataset_embeddings_custom = get_cls_embeddings_for_dataset(\n",
    "            dataset_idx, \n",
    "            dataset_name,\n",
    "            dataset, \n",
    "            config,\n",
    "            tokenizer, \n",
    "            custom_model)\n",
    "        \n",
    "        train_dataset_embeddings = torch.cat(dataset_embeddings_custom['train'], dim=0)\n",
    "        valid_dataset_embeddings = torch.cat(dataset_embeddings_custom['validation'], dim=0)\n",
    "        test_dataset_embeddings = torch.cat(dataset_embeddings_custom['test'], dim=0)\n",
    "\n",
    "\n",
    "        classif = train_linear(train_dataset_embeddings.cpu(), [el['label'] for el in dataset['train']])\n",
    "        valid_preds = evaluate_classifier(classif, valid_dataset_embeddings.cpu())\n",
    "        print('Validation evaluation:\\n')\n",
    "        get_metrics_report([el['label'] for el in dataset['validation']], valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db790ba-7015-4e58-8161-abbea8dd4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = initial_model.to(config.general.device)\n",
    "linear_model = linear_model.to(config.general.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78ecb7d-63d6-4b51-9771-e07b38352a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrpc\n",
      "\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932fc87b20064bd696adb5a1fb747cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train mrpc:   0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502ab1979be34d83a416ada103af9929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation mrpc:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bf8b572f7d4a04b6eeac4d08a7260e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test mrpc:   0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.688181620007579\n",
      "Accuracy 0.6936274509803921\n",
      "-------------------------------\n",
      "\n",
      "Linear:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5850d392503c4420bc5c623773c8ad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train mrpc:   0%|          | 0/3668 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shapkin/effective-inference/utils/attentions/bert/linear.py:62: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  result += namespace['cur_result'].T\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29eb52891b14e0196aa48b92f5453ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation mrpc:   0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aec290d2744fe08b36cf792203ebd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test mrpc:   0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.6775067493060573\n",
      "Accuracy 0.6936274509803921\n",
      "-------------------------------\n",
      "wic\n",
      "\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc01e873a44d6fbd035f1327e4fd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train wic:   0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4e4228555b44c4b161b42e45b13738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation wic:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a66d3daafa74758aa757b6d1f227786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test wic:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.6009986605735895\n",
      "Accuracy 0.6018808777429467\n",
      "-------------------------------\n",
      "\n",
      "Linear:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc238a4fe9c947ce9c3570f35d308aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train wic:   0%|          | 0/5428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe47da21edf445f79f2d5891c3487e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation wic:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54da8c60958a4275a3f739316242e97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test wic:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation evaluation:\n",
      "\n",
      "Weighted F1 0.5829245514868518\n",
      "Accuracy 0.5830721003134797\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "check_results(linear_model, initial_model, eval_datasets, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9d6f7-7774-4860-bc09-89cecca61d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
